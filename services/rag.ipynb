{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community import embeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain.schema import Document \n",
    "# from dotenv import load_dotenv \n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import os \n",
    "import shutil \n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFS_DIR = \"pdfs\"\n",
    "def load_documents():\n",
    "  document_loader = PyPDFDirectoryLoader(PDFS_DIR) \n",
    "  return document_loader.load() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(documents: list[Document]):\n",
    "\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50,\n",
    "    length_function=len, \n",
    "    add_start_index=True,\n",
    "  )\n",
    "\n",
    "  chunks = text_splitter.split_documents(documents)\n",
    "  print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "  return chunks \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"chromadb\"\n",
    "\n",
    "def save_to_chroma(chunks: list[Document]):\n",
    "  if os.path.exists(CHROMA_PATH):\n",
    "    shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "  db = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embeddings.OllamaEmbeddings(model='llama3'),\n",
    "    persist_directory=CHROMA_PATH\n",
    "  )\n",
    "\n",
    "  db.persist()\n",
    "  print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 2 documents into 28 chunks.\n",
      "Saved 28 chunks to chromadb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghav/Development/personal/stock_news_briefer/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "def initialize_data_store():\n",
    "  documents = load_documents() \n",
    "  chunks = split_text(documents) \n",
    "  save_to_chroma(chunks) \n",
    "\n",
    "initialize_data_store()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    " - -\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(query_text):\n",
    "\n",
    "  embedding_function = embeddings.OllamaEmbeddings(model='llama3')\n",
    "\n",
    "  db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "  \n",
    "  results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "\n",
    "  if len(results) == 0 or results[0][1] < 0.7:\n",
    "    print(f\"Unable to find matching results.\")\n",
    "\n",
    "\n",
    "  context_text = \"\\n\\n - -\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    " \n",
    "\n",
    "  prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "  prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "  \n",
    "\n",
    "  response = ollama.chat(\n",
    "    model='llama3',\n",
    "    messages=[\n",
    "        {\n",
    "          'role': 'user',\n",
    "          'content':prompt,\n",
    "        },\n",
    "    ],\n",
    "  )\n",
    "\n",
    "  response_text = response['message']['content']\n",
    "\n",
    "  sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    " \n",
    "  formatted_response = f\"Response: \\n{response_text}\\nSources: {sources}\"\n",
    "  return formatted_response, response_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghav/Development/personal/stock_news_briefer/.venv/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'page': 0, 'source': 'pdfs/9d5b6cde-ba1a-46e0-8d4c-5a13d7bd16fd.pdf', 'start_index': 491}, page_content='Obligations and Disclosure Requirements)  Regulations, 2015 [“SEBI LODR \\nRegulations”]  and our intimations dated May 22, 2023, and January 25, 2024 \\n \\nIn furtherance to intimations dated May 22, 2023, and January 25, 2024, on rebranding of the'), -19540.330833133397), (Document(metadata={'page': 1, 'source': 'pdfs/9d5b6cde-ba1a-46e0-8d4c-5a13d7bd16fd.pdf', 'start_index': 554}, page_content='bankers and other lenders, credit rating agencies etc., the brand name ‘Sammaan’ connotes \\nand conveys what our business stands for and how it is r un. \\n \\nStrategically, our business will continue to be retail -focused built on the two loan products of'), -20953.529842667973), (Document(metadata={'page': 1, 'source': 'pdfs/9d5b6cde-ba1a-46e0-8d4c-5a13d7bd16fd.pdf', 'start_index': 808}, page_content='affordable home loans and mortgage-backed loans to micro, medium and small businesses. \\nWe will pursue AUM growth in an asset-light model, working as an or igination-engine to source \\nloans in co -lending and sell -down partnerships with banks and financial institutions. The'), -21435.75937890718)]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find matching results.\n",
      "Response: Unfortunately, there is no mention of a new email address for the company in the provided context. The text only discusses rebranding, business strategy, loan products, and partnerships with banks and financial institutions, but does not provide any information about an updated email address.\n",
      "Sources: ['pdfs/9d5b6cde-ba1a-46e0-8d4c-5a13d7bd16fd.pdf', 'pdfs/9d5b6cde-ba1a-46e0-8d4c-5a13d7bd16fd.pdf', 'pdfs/9d5b6cde-ba1a-46e0-8d4c-5a13d7bd16fd.pdf']\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter your question: \")\n",
    "formatted_response, response_text = query_rag(query)\n",
    "print(formatted_response)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
